# Paper Summary

此文档作阅读过的paper的总结性表格，请各位把相关的论文总结写一条在此表格中方便互享

- 若你觉得有可以添加的列或者比较新颖的点，请自行添加一列，写上对应内容。

- 另外若你觉得还有更深入的讲解，可以单独写一个文档，在表格中填入文档连接，同时上传到仓库。

|                   标题xxxxxxxxxxxxxxxxxxx                    | 会议xxxxx  |    摘要翻译xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx     | 目标xxxx |             算法/实现方式xxxxxxxxxxxxxxxxxxxxxx              |                控制机制xxxxxxxxxxxxxxxxxxxxxx                |                  效果xxxxxxxxxxxxxxxxxxxxxx                  | 其他xxxxxxxxxxxxxxxxxxxxxx |              详细文档链接xxxxxxxxxxxxxxxxxxxxxx              |
| :----------------------------------------------------------: | :--------: | :----------------------------------------------------------: | :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------------------: | :----------------------------------------------------------: |
| AXNet: ApproXimate computing using an end-to-end trainable neural network | ICCAD 2018 | 基于神经网路的近似计算是一个对容错性很高的应用节省大量计算的通用的架构。为保证近似的精度，现有的工作采用了两个神经网络的架构，一个为近似器，一个为预测器。近似器用于近似j计算结果，预测器预测给定数据是否能够安全地被预测（在给定精度的情况下）。但是将两个网络结合起来是不简单而且费时的，因为他们有不同的目标函数，他们需要被不同地训练。本文提出了一种新的网络架构AXNet将以上两种网络融合成一个整体的网络。在受到多任务学习（Multi-task Learning）的启发后设计的AXNet网络模型大大提高了激活率，而且减少了近似的误差。用于训练的资源也大大减小了。实验结果表明于前人的工作进行对比，此网络结构下有50.7%的激活率和训练时间被减少了 | 近似计算 | 设计一个可端到端训练的approximator和predictor结合的网络。具体方法是在predictor和approximator的每一层之间加入一个标量的对应元素的乘法算子，这样后向传播梯度的时候可以响应调整predictor的参数 | 在approximator的每一层和predictor的输出进行对于元素相乘。是用scalar product来控制。 | 预测准确率提高了，而且对于预测样本的近似误差更小（详见链接） |                            | <https://github.com/acada-sjtu/EdgeTraining/blob/master/Doc/Weekly-Report/PaperReadingNotes/AXNet%20ApproXimate%20computing%20using%20an%20end-to-end%20trainable%20neural%20network.md> |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |
|                                                              |            |                                                              |          |                                                              |                                                              |                                                              |                            |                                                              |



